{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "631eccf85cdbbcfa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# <span style=\"color:orange; font-weight:bold;\">Regulatory AI Search Engine with Llama</span> <br>\n",
    "### <span style=\"color:orange; font-weight:bold;\">A Local Retrieval-Augmented Generation (RAG) </span> <br> <br>\n",
    "*created with ❤️ by Daniel Jacobowitz & Prasoon Singh*"
   ],
   "id": "9636b4ee208afb9f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "5cb32a2ff8dfdbe7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **I. What tha fuck is a Retrieval-Augmented Generation (RAG)?**",
   "id": "1fb7cd1939623f79"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Retrieval augmented generation (RAG) is a technique that combines information retrieval technique with language model generation to improve the accuracy and credibility of the generated text, and to better ground the model’s response in evidence. In RAG, a language model is augmented with an external knowledge base or a set of documents that is passed into the context window. <br>\n",
    "\n",
    "At the core of RAG lies the seamless integration of two key components:\n",
    "1. **Vector Databases/ Retriever:** These specialized databases store and index information in a vector representation (so called vector embedding), enabling similarity searches and retrieval of relevant data.\n",
    "2. **Large Language Models (LLMs)/ Generator:** Takes the retrieved information and the original query as input, and produced human-like output that incorporates both factual knowledge and contextual understanding. <br>\n",
    "\n",
    "By combining the retrieved information with the LLM`s language generation capabilities, the RAG system can produce more accurate, relevant and credible responses compared to using the LLM alone. <br>\n",
    "\n",
    "To understand the concept better, let`s compare in the following the basic system with a RAG system. Let’s start with a basic system. A basic system is composed of a prompt, a model, and an output parser. The basic system illustrates the core idea of using LLMs in a structured way by defining the input (prompt), the processing step (model), and the output handling (output parser). It serves as a foundational concept that can be extended and combined with other components to build more complex chains and applications. Below, an illustration of the basic chain architecture is provided. <br> <br>\n",
    " ![basic_chain.png](Basic_chain.png) <br> <br>\n",
    "\n",
    "\n",
    "A RAG system on the other hand adds context when responding to questions. Let’s break down RAG system by a RAG prompt, a RAG retriever, and a RAG chain as illustrated in the following. <br> <br>\n",
    " ![basic_chain.png](RAG_chain.png) <br> <br>\n",
    "\n",
    "Here`s a step-by-step breakdown how a RAG system is structured and how it works: <br>\n",
    "***Data preparation:***\n",
    "1. The raw data sources (e.g. PDF files) are loaded.\n",
    "2. The information of the loaded data sources are extracted (e.g. text from the PDF files).\n",
    "3. The huge amount of text is spilled/ chunked to smaller pieces.\n",
    "4. The chunks are then indexed into a numerical vector  (Embedding) and stored as a vector database (vector store). <br> <br>\n",
    "***RAG:*** <br>\n",
    "1. A user provides a query or prompt to the RAG system.\n",
    "2. The query is then converted to vector embeddings, so the information can be processed for the next step.\n",
    "3. The retriever component searches through the created vector database to find the most relevant information related to the query (vector similarity search).\n",
    "3. The retrieved relevant data/ information along with the original query, is passed to the generator component (the LLM).\n",
    "4. The LLM generates a response that incorporates the retrieved information, providing a more accurate and context-aware answer to the user`s query.\n",
    "\n",
    "By combining the strength of LLMs and information retrieval techniques, RAG systems offer a promising approach to overcome some of the limitations of LLMs and enhancing the quality and reliability of generated text. The benefits of using RAG in enhancing LLM credibility and accuracy are numerous:\n",
    "1. **Improved factual accuracy:** By incorporating relevant information from reliable sources, RAG systems can help reduce the instances of factual errors of inconsistencies in the generated text.\n",
    "2. **Enhanced credibility:** RAG systems can provide citations or references to the sources of information used in the generated response, increasing the credibility and trustworthiness of the output.\n",
    "3. **Access to up-to-date information:** RAG systems can be designed to retrieve information from continuously updated sources, ensuring that the generated responses are based on the most recent and relevant information available.\n",
    "4. **Customization and domain-specific knowledge:** RAG systems can be tailored to specific domains or use cases by incorporating domain-specific knowledge bases or documents, enabling the generation of more accurate and relevant responses within a particular field or context. <br>\n",
    "\n",
    "**Useful links:**\n",
    "- https://medium.com/@dminhk/retrieval-augmented-generation-rag-explained-b1dd89979681\n",
    "\n"
   ],
   "id": "63c51079b02753d7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "12d0a4d9e89b85eb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **II. Step-by-step instructions to build a RAG**",
   "id": "5156c87447523b37"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "5fe3e43704ba8f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **Step 1: Installing and loading the necessary Modules (incl. description)**",
   "id": "1b876b55fdd67d24"
  },
  {
   "cell_type": "code",
   "id": "24fae24c-433b-4860-badd-e0eb20759f4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T22:09:58.005979Z",
     "start_time": "2024-10-14T22:09:57.976666Z"
    }
   },
   "source": [
    "#!pip install langchain-community==0.2.4 langchain==0.2.3 faiss-cpu==1.8.0 unstructured==0.14.5 unstructured[pdf]==0.14.5 transformers==4.41.2 sentence-transformers==3.0.1\n",
    "\n",
    "import os # --> interacts with the operating system, like creating files and directories, management of files and directories, input, output, environment variables etc.\n",
    "\n",
    "#import pandas as pd # --> Analyses data and allows to manipulate data as dataframes\n",
    "\n",
    "from langchain_community.llms import Ollama  # --> LLM classes provide access to the large language model (in this case locally to Ollama) APIs and services.\n",
    "\n",
    "from langchain.document_loaders import UnstructuredFileLoader # --> Loads data from a source as Documents, which are a piece of text and associated metadata.\n",
    "                                                              # --> In this case, the file loader uses the unstructured partition function and will automatically detect the file type.\n",
    "\n",
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader # --> Loads data from a source as Documents, which are a piece of text and associated metadata.\n",
    "                                                                # --> In this case, the file loader loads a directory with PDF files using pypdf and chunks at character level. The loader also stores page numbers in metadata.\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings #--> Convert the text of the PDF files using Embeddings models into numerical vectors\n",
    "#from langchain_community.embeddings.ollama import OllamaEmbeddings #--> Convert the text of the PDF files using Embeddings models into numerical vectors\n",
    "#from langchain_ollama import OllamaEmbeddings #--> Convert the text of the PDF files using Embeddings models into numerical vectors\n",
    "\n",
    "from langchain_community.vectorstores import FAISS # --> Creates a local vector store to store the created embeddings of the PDF files. LangChain has a number of built-in document transformers that make it easy to split, combine, filter, and otherwise manipulate documents.\n",
    "from langchain_chroma import Chroma # --> Creates a local vector store to store the created embeddings of the PDF files.\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter # --> Splits a long document (in our case the PDF files) into smaller chunks that can fit into the model`s context window. LangChain has a number of built-in document transformers that make it easy to split, combine, filter, and otherwise manipulate documents.\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # --> Splits a long document (in our case the PDF files) into smaller chunks that can fit into the model`s context window. LangChain has a number of built-in document transformers that make it easy to split, combine, filter, and otherwise manipulate documents.\n",
    "from langchain_experimental.text_splitter import SemanticChunker #--> Splits a long document (in our case the PDF files) into smaller chunks that can fit into the model`s context window. LangChain has a number of built-in document transformers that make it easy to split, combine, filter, and otherwise manipulate documents.\n",
    "\n",
    "from langchain.chains import RetrievalQA # --> Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step. This chain first does a retrieval step to fetch relevant documents, then passes those documents into an LLM to generate a response.\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate # --> A prompt for a language model is a set of instructions or input provided by a user to guide the model's response, helping it understand the context and generate relevant and coherent language-based output, such as answering questions, completing sentences, or engaging in a conversation.\n",
    "#from langchain.memory import ConversationBufferMemory # --> Creates a conversational memory that allows a LLM to remember previous interactions/ chats with the user. It helps to manage and store conversation history in a structured way and to maintain the context of a conversation over multiple interactions.\n",
    "\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler # --> LangChain provides a callbacks system that allows you to hook into the various stages of your LLM application. In this case, it is a callback for streaming.\n",
    "                                                                                # --> Streaming: process of incrementally receiving and processing data generated by a Large Language Model (LLM) as it is produced, rather than waiting for the entire response to be generated before displaying it.\n",
    "from langchain.callbacks.manager import CallbackManager # --> LangChain provides a callbacks system that allows you to hook into the various stages of your LLM application. In this case, it is to manage callbacks.\n",
    "\n",
    "import streamlit as st # --> Streamlit is a free and open-source framework to rapidly build and share beautiful machine learning and data science web apps.\n",
    "\n",
    "import time #This module provides various time-related functions. \n",
    "\n",
    "if not os.path.exists('C:/Users/49171/OneDrive/Desktop/Programieren/Python/PDF_test/Final/pdfFiles'): # Check if the folder does not exist\n",
    "    os.makedirs('C:/Users/49171/OneDrive/Desktop/Programieren/Python/PDF_test/Final/pdfFiles') # create a folder in the specified path if it does not exist already\n",
    "\n",
    "if not os.path.exists('C:/Users/49171/OneDrive/Desktop/Programieren/Python/PDF_test/Final/vectorDB'): # Check if the folder does not exist\n",
    "    os.makedirs('C:/Users/49171/OneDrive/Desktop/Programieren/Python/PDF_test/Final/vectorDB') # create a folder in the specified path if it does not exist already\n",
    "\n",
    "switch = 0"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "2617cb33f823ebfe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Step 2: Uploading the PDF files as text documents, chunking the documents and convert the documents to numerical vectors incl. indexation with vector embeddings and store them into a local database.** <br> <br>",
   "id": "5d32c56a9c2e2475"
  },
  {
   "cell_type": "code",
   "id": "378c5f69-192c-4db7-bc73-68d1fdbc1b2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T22:10:02.560213Z",
     "start_time": "2024-10-14T22:10:02.533507Z"
    }
   },
   "source": [
    "# 1. Upload relevant PDF files\n",
    "DATA_PATH = \"C:/Users/49171/OneDrive/Desktop/Programieren/Python/PDF_test\" # Directory where the relevant PDFs are stored\n",
    "\n",
    "if switch == 1:\n",
    "    def load_documents(DATA_PATH): # defines a function named 'load_documents' that takes one parameter, 'DATA_PATH'.\n",
    "        document_loader = PyPDFDirectoryLoader(DATA_PATH) # creates the class 'PyPDFDirectoryLoader' designed to load PDF documents from a specified directory.\n",
    "        return document_loader.load() # the load method on the document_loader instance and returns the result. The load method is expected to read and load the PDF documents from the directory specified by DATA_PATH. The load method loads data into Document objects.\n",
    "\n",
    "    documents = load_documents(DATA_PATH) # the variable 'documents' is a object containing for every list elements a page of the PDF files.\n",
    "    \n",
    "    # --> Plausibility check\n",
    "    print(\"\\033[92mThe upload of the PDF files was successful!\\033[0m\")\n",
    "    print('')\n",
    "    print('CRR:')\n",
    "    print (documents[0])\n",
    "    print('')\n",
    "    print('Banking Act:')\n",
    "    print(documents[337])\n",
    "    print('')\n",
    "    print('MaRisk:')\n",
    "    print(documents[600])\n",
    "    print('')"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "e5d82c99-3c23-4870-b5ac-959cae3052e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T22:10:05.787245Z",
     "start_time": "2024-10-14T22:10:05.771616Z"
    }
   },
   "source": [
    "# 2. Chunking the documents\n",
    "\n",
    "if switch == 1:\n",
    "    #text_splitter = SemanticChunker(embeddings=HuggingFaceEmbeddings(), breakpoint_threshold_type=\"percentile\") # Apply the chunking based on cosine similarity. There a many breakpoint threshold types.\n",
    "    #text_chunks = text_splitter.split_documents(documents) # #  splits the documents into chunks based on the similarity\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter( # function to split documents into chunks\n",
    "                chunk_size=1500, # sets the maximum size of each chunk to 1500 characters.\n",
    "                chunk_overlap=200, #  sets the overlap between consecutive chunks to 200 characters. Overlapping helps to ensure that context is preserved across chunks.\n",
    "                length_function=len # specifies that the length of the chunks will be measured using the len function, which counts the number of characters.\n",
    "            )\n",
    "\n",
    "    text_chunks = text_splitter.split_documents(documents) #  splits the documents into chunks based on the specified chunk_size and chunk_overlap."
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "7cb5e2be-76e5-49f3-a50a-d336be3d30e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T22:10:10.605390Z",
     "start_time": "2024-10-14T22:10:09.015134Z"
    }
   },
   "source": [
    "# 3. Convert the splitted text into Vector Embeddings incl. indexation and store the created vector data base locally\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings() # The used embeddings model is from HuggingFace\n",
    " #embeddings = OllamaEmbeddings(\n",
    "    #        model = \"llama3.2:3b\",\n",
    "    #  base_url = 'http://localhost:11434'\n",
    "    #    )\n",
    "\n",
    "if switch == 1:\n",
    "   # Create and save the vector store\n",
    "    knowledge_base = FAISS.from_documents(text_chunks, embeddings) # The created chunks are converted to numerical vectors and stored in a FAISS vector database.\n",
    "    knowledge_base.save_local('C:/Users/49171/OneDrive/Desktop/Programieren/Python/PDF_test/Final/vectorDB') # The created FAISS vector database is stored locally in the given directory.\n",
    "\n",
    "    print(\"\\033[92mThe Embedding was successful!\\033[0m\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_23080\\1986862643.py:3: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embeddings = HuggingFaceEmbeddings() # The used embeddings model is from HuggingFace\n",
      "C:\\Users\\49171\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "f5a9c707b20093f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Step 3: Declare the created data base as retriever and test the retrieval based on a cosine similarity search** <br> <br>",
   "id": "eba32552813cb0a1"
  },
  {
   "cell_type": "code",
   "id": "ab0d7fda-3c61-49db-b211-275c083175b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T22:10:22.622960Z",
     "start_time": "2024-10-14T22:10:22.547207Z"
    }
   },
   "source": [
    "# 1. Declaration of the retriever based on the created database\n",
    "\n",
    "retriever = FAISS.load_local( # This method converts the stored vector database into a retriever object. A retriever is typically used to search and retrieve relevant documents or information. In other words, it will be the base for the search as the retrieved information will then later be passed to the LLM.\n",
    "    'C:/Users/49171/OneDrive/Desktop/Programieren/Python/PDF_test/Final/vectorDB', # Directory of the locally stored vector database\n",
    "    embeddings, # Parameter to declare, that the embeddings should be loaded.\n",
    "    allow_dangerous_deserialization=True).as_retriever(search_kwargs={\"k\":5}) # Defines, that the 5 most similar text chunks should be output in the course of a cosine similarity search."
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T12:50:03.038242Z",
     "start_time": "2024-10-14T12:50:02.927332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. Test of the retrieval based on a test query\n",
    "\n",
    "query = \"What is the minimum Probability of Default?\" # Test query\n",
    "results = retriever.invoke(query) # Gets relevant documents based on a cosine similarity search for the query.\n",
    "for doc in results: # Function to output the content of the retrieved text chunks, the source and the page number based on the available metadata.\n",
    "    #print(\"Page Content:\", doc.page_content) # Outputs the 5 most similar text chunks\n",
    "    source_path = doc.metadata.get('source', 'No source available') # Prints the name of the whole directory\n",
    "    source_filename = os.path.basename(source_path) # Prints the name of the PDF file\n",
    "    print(\"Source:\", source_filename)\n",
    "    print(\"Page:\", doc.metadata.get('page', 'No page available'))\n",
    "    print(\"\\n\")"
   ],
   "id": "a55dee83927e8408",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: CRR.pdf\n",
      "Page: 101\n",
      "\n",
      "\n",
      "Source: CRR.pdf\n",
      "Page: 101\n",
      "\n",
      "\n",
      "Source: KWG.pdf\n",
      "Page: 236\n",
      "\n",
      "\n",
      "Source: KWG.pdf\n",
      "Page: 236\n",
      "\n",
      "\n",
      "Source: CRR.pdf\n",
      "Page: 96\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "a30655c51dd0d433"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Step 4: Passing the retrieved information to the LLM** <br> <br>",
   "id": "138e0144ecd58b10"
  },
  {
   "cell_type": "code",
   "id": "154f2f47-1bc8-4d48-85f6-0775e02f00cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T22:10:31.077993Z",
     "start_time": "2024-10-14T22:10:31.062327Z"
    }
   },
   "source": [
    "# 1. Create a prompt template to pass the retrieved information and the original query in a standardised format to the LLM. \n",
    "\n",
    "# The input variable needs to be declared in the next steps. \"Context\" is the retrieved information and \"question\" the original query. \n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE) # Create a ChatPromptTemplate object to pass it to the LLM.\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T22:12:02.231018Z",
     "start_time": "2024-10-14T22:12:02.215391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. Declare the preferred LLM to generate the answer for the query based on the retrieved information.\n",
    "\n",
    "llm = Ollama( # The local ollama model is used for the generation of the answer.\n",
    "    model=\"llama3.2:3b\", # Model version\n",
    "    temperature=0, # controls the randomness of the model's output. A higher temperature value (e.g., 1.5) makes the model's responses more random and creative, while a lower temperature value (e.g., 0.9) makes the responses more deterministic and focused. The default value is typically around 1.1. The chosen value of 0 means the model will produce the most deterministic and predictable output, essentially always choosing the highest probability token at each step. This makes the responses very repetitive and lacks the creativity or variability you'd see with higher temperatures. It's like playing it safe and not taking any chances.\n",
    "    base_url = 'http://localhost:11434', # Local base URL\n",
    ")"
   ],
   "id": "90183e6857da198c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\49171\\AppData\\Local\\Temp\\ipykernel_23080\\538348336.py:3: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
      "  llm = Ollama( # The local ollama model is used for the generation of the answer.\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T22:15:23.998088Z",
     "start_time": "2024-10-14T22:15:23.951544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "qa_chain = RetrievalQA.from_chain_type( # Creates a RetrievalQA object, which creates a connection (\"chain\") between the retrieved information and the declared LLM.\n",
    "    llm, # Specifies the language model to be used for generating answers, which has been declared in the previous step.\n",
    "    retriever=retriever, # Specifies the retriever to be used for fetching relevant documents or information from the stored vector database.\n",
    "    chain_type_kwargs={ # A dictionary of additional keyword arguments for the chain type.\n",
    "                \"verbose\": True, # Ensures that verbose mode is enabled within the chain.\n",
    "                \"prompt\": prompt_template } # Specifies the prompt template to be passed to the LLM containing the retrieved information and the original query,\n",
    ")"
   ],
   "id": "c607432440b3fd09",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "95a758f7bf66fe92"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Step 5: Generate an answer from the LLM based on the retrieved information** <br> <br>",
   "id": "a96880b5c4a8d234"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T22:17:16.963212Z",
     "start_time": "2024-10-14T22:15:30.163278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "question = input(\"How can I help you?\") # Query\n",
    "response = qa_chain.invoke({\"query\": question}) # Gets the answer from the LLM based on the created \"Chain\" with the method \"invoke\", that calls the chain based on an input (here: the question).\n",
    "print(response[\"result\"]) # Prints the generated answer\n",
    "\n",
    "results = retriever.invoke(question) # Gets relevant documents based on a cosine similarity search for the query.\n",
    "for doc in results:\n",
    "    source_path = doc.metadata.get('source', 'No source available')\n",
    "    source_filename = os.path.basename(source_path)\n",
    "    print(\"Source:\", source_filename)\n",
    "    print(\"Page:\", doc.metadata.get('page', 'No page available'))\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n"
   ],
   "id": "535c799542375422",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new StuffDocumentsChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mHuman: \n",
      "Answer the question based only on the following context:\n",
      "\n",
      "default in accordance with Article 166(1) shall be treated in \n",
      "the same manner as specific credit risk adjustments. Specific \n",
      "credit risk adjustments on exposures in default shall not be \n",
      "used to cover expected loss amounts on other exposures. \n",
      "Expected loss amounts for securitised exposures and general \n",
      "and specific credit risk adjustments related to these exposures \n",
      "shall not be included in this calculation.  \n",
      "S e c t i o n 4  \n",
      "P D , L G D a n d m a t u r i t y  \n",
      "S u b - S e c t i o n 1  \n",
      "E x p o s u r e s t o c o r p o r a t e s , i n s t i t u t i o n s a n d \n",
      "c e n t r a l g o v e r n m e n t s a n d c e n t r a l b a n k s  \n",
      "Article 160  \n",
      "Probability of default (PD)  \n",
      "1. The PD of an exposure to a corporate or an institution \n",
      "shall be at least 0,03 %.  \n",
      "2. For purchased corporate receivables in respect of which an \n",
      "institution is not able to estimate PDs or institution's PD \n",
      "estimates do not meet the requirements set out in Section 6, \n",
      "the PDs for these exposures shall be determined according to \n",
      "the following methods:  \n",
      "(a) for senior claims on purchased corporate receivables PD \n",
      "shall be the institutions estimate of EL divided by LGD \n",
      "for these receivables;  \n",
      "(b) for subordinated claims on purchased corporate receivables \n",
      "PD shall be the institution's estimate of EL;EN L 176/102 Official Journal of the European Union 27.6.2013\n",
      "\n",
      "default in accordance with Article 166(1) shall be treated in \n",
      "the same manner as specific credit risk adjustments. Specific \n",
      "credit risk adjustments on exposures in default shall not be \n",
      "used to cover expected loss amounts on other exposures. \n",
      "Expected loss amounts for securitised exposures and general \n",
      "and specific credit risk adjustments related to these exposures \n",
      "shall not be included in this calculation.  \n",
      "S e c t i o n 4  \n",
      "P D , L G D a n d m a t u r i t y  \n",
      "S u b - S e c t i o n 1  \n",
      "E x p o s u r e s t o c o r p o r a t e s , i n s t i t u t i o n s a n d \n",
      "c e n t r a l g o v e r n m e n t s a n d c e n t r a l b a n k s  \n",
      "Article 160  \n",
      "Probability of default (PD)  \n",
      "1. The PD of an exposure to a corporate or an institution \n",
      "shall be at least 0,03 %.  \n",
      "2. For purchased corporate receivables in respect of which an \n",
      "institution is not able to estimate PDs or institution's PD \n",
      "estimates do not meet the requirements set out in Section 6, \n",
      "the PDs for these exposures shall be determined according to \n",
      "the following methods:  \n",
      "(a) for senior claims on purchased corporate receivables PD \n",
      "shall be the institutions estimate of EL divided by LGD \n",
      "for these receivables;  \n",
      "(b) for subordinated claims on purchased corporate receivables \n",
      "PD shall be the institution's estimate of EL;EN L 176/102 Official Journal of the European Union 27.6.2013\n",
      "\n",
      "Section 53n \n",
      " \n",
      " 223 2 the default fund does not reach the minimum amount referred to in Article 41 (1) \n",
      "sentence 2 of Regulation (EU) No 648/2012 in two reporting periods pursuant to section 53j (1),  \n",
      "3 the default fund and the other financial resources are not sufficient on two reporting dates pursuant to section 53j (1) within one calendar year to cover a default of the two \n",
      "clearing members referred t o in Article 43 (2) of Regulation (EU) No 648/2012,  \n",
      "4 the credit lines or similar arrangements which exist to cover the liquidity needs \n",
      "referred to in Article 44 (1) of Regulation (EU) No 648/2012, also in conjunction with regulatory technical standards re ferred to in paragraph (2) thereof, are not sufficient \n",
      "on two reporting dates pursuant to section 53j (1) to cover the liquidity risk with regard to the default of at least the two clearing members to which the central counterparty \n",
      "has the largest exposure s. \n",
      "5 the central counterparty has in two reporting periods pursuant to section 53j (1) \n",
      "accepted in each case more than 3% of the overall collateral without taking into account the requirements referred to in Article 46 (1) of Regulation (EU) No 648/2012, \n",
      "also in conjunction with regulatory technical standards referred to in paragraph (3) \n",
      "thereof or  \n",
      "6 the central counterparty has in two reporting periods pursuant to section 53j (1) invested in each case more than 3% of the overall collateral without taking i nto\n",
      "\n",
      "Section 53n \n",
      " \n",
      " 223 2 the default fund does not reach the minimum amount referred to in Article 41 (1) \n",
      "sentence 2 of Regulation (EU) No 648/2012 in two reporting periods pursuant to section 53j (1),  \n",
      "3 the default fund and the other financial resources are not sufficient on two reporting dates pursuant to section 53j (1) within one calendar year to cover a default of the two \n",
      "clearing members referred t o in Article 43 (2) of Regulation (EU) No 648/2012,  \n",
      "4 the credit lines or similar arrangements which exist to cover the liquidity needs \n",
      "referred to in Article 44 (1) of Regulation (EU) No 648/2012, also in conjunction with regulatory technical standards re ferred to in paragraph (2) thereof, are not sufficient \n",
      "on two reporting dates pursuant to section 53j (1) to cover the liquidity risk with regard to the default of at least the two clearing members to which the central counterparty \n",
      "has the largest exposure s. \n",
      "5 the central counterparty has in two reporting periods pursuant to section 53j (1) \n",
      "accepted in each case more than 3% of the overall collateral without taking into account the requirements referred to in Article 46 (1) of Regulation (EU) No 648/2012, \n",
      "also in conjunction with regulatory technical standards referred to in paragraph (3) \n",
      "thereof or  \n",
      "6 the central counterparty has in two reporting periods pursuant to section 53j (1) invested in each case more than 3% of the overall collateral without taking i nto\n",
      "\n",
      "— where institutions apply the LGD values set out in \n",
      "Article 161(1), RW shall be 0;  \n",
      "— where institutions use own estimates of LGDs, RW shall \n",
      "be RW ¼ maxf0,12 :5 · ðLGD  – EL  BE Þg; \n",
      "where the expected loss best estimate (hereinafter referred \n",
      "to as  'EL BE ') shall be the institution's best estimate of \n",
      "expected loss for the defaulted exposure in accordance \n",
      "with Article 181(1)(h);  \n",
      "(iii) if 0 < PD < 1  \n",
      "RW ¼ 8 \n",
      "> > :LGD  · N 8 \n",
      "> > : 1 ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ  \n",
      "1 – R p · GðPDÞ þ ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ  \n",
      "R \n",
      "1 – R r \n",
      "· Gð0:999Þ 9 \n",
      "> > ; – LGD  · PD 9 \n",
      "> > ; · 1 þ ðM – 2,5Þ · b \n",
      "1 – 1,5 · b · 12,5 · 1,06  \n",
      "where:  \n",
      "N(x) = the cumulative distribution function for a standard normal random variable (i.e. the prob ­\n",
      "ability that a normal random variable with mean zero and variance of one is less than or equal \n",
      "to x);  \n",
      "G(Z) = denotes the inverse cumulative distribution function for a standard normal random variable \n",
      "(i.e. the value x such that N(x) = z)  \n",
      "R = denotes the coefficient of correlation, is defined as  \n",
      "R ¼ 0:12 · 1 – e – 50 · PD \n",
      "1 – e – 50 þ 0 :24 · 8 \n",
      "> > > : 1 – 1 – e – 50 · PD \n",
      "1 – e – 50 9 \n",
      "> > > ; \n",
      "b = the maturity adjustment factor, which is defined as  \n",
      "b ¼ ð0:11852 – 0 :05478 · lnðPDÞÞ 2 . \n",
      "2. For all exposures to large financial sector entities, the co-efficient of correlation of paragraph 1(iii) is \n",
      "multiplied by 1,25. For all exposures to unregulated financial entities, the coefficients of correlation set out\n",
      "\n",
      "---\n",
      "\n",
      "Answer the question based on the above context: What is the minimum Probability of Default?\n",
      "\u001B[0m\n",
      "The minimum Probability of Default (PD) for an exposure to a corporate or institution is at least 0.03%.\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "The minimum Probability of Default (PD) for an exposure to a corporate or institution is at least 0.03%.\n",
      "Source: CRR.pdf\n",
      "Page: 101\n",
      "\n",
      "\n",
      "Source: CRR.pdf\n",
      "Page: 101\n",
      "\n",
      "\n",
      "Source: KWG.pdf\n",
      "Page: 236\n",
      "\n",
      "\n",
      "Source: KWG.pdf\n",
      "Page: 236\n",
      "\n",
      "\n",
      "Source: CRR.pdf\n",
      "Page: 96\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "321b247a8186db13"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# III. Appendix",
   "id": "80a9c1a16e9643f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **1. Code to generate answers for the validation**",
   "id": "3e389556b6127bab"
  },
  {
   "cell_type": "code",
   "id": "939c4925-440f-458e-85be-4b8c772ba0d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T21:46:23.966802Z",
     "start_time": "2024-10-13T21:45:31.495871Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel('C:/Users/49171/OneDrive/Desktop/Programieren/Python/PDF_test/Final/Hackathon_Fragen.xlsx')\n",
    "\n",
    "\n",
    "for index, question in df['Question'].items():\n",
    "    response = qa_chain.invoke({\"query\": question})\n",
    "    df.at[index, 'Provided Answer'] = response[\"result\"]\n",
    "    print(\"Question no. \" + str(index+1) + \" was processed\")\n",
    "    print(\"__________\")\n",
    "\n",
    "df.to_excel('C:/Users/49171/OneDrive/Desktop/Programieren/Python/PDF_test/Final/output_RAG.xlsx', index=False)\n",
    "print(\"All Questions Processed\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new StuffDocumentsChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mHuman: \n",
      "Answer the question based only on the following context:\n",
      "\n",
      "1. PDs shall be determined according to the methods for \n",
      "corporate exposures.  \n",
      "The following minimum PDs shall apply:  \n",
      "(a) 0,09 % for exchange traded equity exposures where the \n",
      "investment is part of a long-term customer relationship;  \n",
      "(b) 0,09 % for non-exchange traded equity exposures where the \n",
      "returns on the investment are based on regular and periodic \n",
      "cash flows not derived from capital gains;  \n",
      "(c) 0,40 % for exchange traded equity exposures including \n",
      "other short positions as set out in Article 155(2);  \n",
      "(d) 1,25 % for all other equity exposures including other short \n",
      "positions as set out in Article 155(2).EN L 176/106 Official Journal of the European Union 27.6.2013\n",
      "\n",
      "1. PDs shall be determined according to the methods for \n",
      "corporate exposures.  \n",
      "The following minimum PDs shall apply:  \n",
      "(a) 0,09 % for exchange traded equity exposures where the \n",
      "investment is part of a long-term customer relationship;  \n",
      "(b) 0,09 % for non-exchange traded equity exposures where the \n",
      "returns on the investment are based on regular and periodic \n",
      "cash flows not derived from capital gains;  \n",
      "(c) 0,40 % for exchange traded equity exposures including \n",
      "other short positions as set out in Article 155(2);  \n",
      "(d) 1,25 % for all other equity exposures including other short \n",
      "positions as set out in Article 155(2).EN L 176/106 Official Journal of the European Union 27.6.2013\n",
      "\n",
      "tution for its estimates;  \n",
      "(d) the institution shall remain responsible for the integrity of \n",
      "its rating systems;  \n",
      "(e) the institution shall maintain sufficient in-house under ­\n",
      "standing of its rating systems, including the ability to effec ­\n",
      "tively monitor and audit the rating process.  \n",
      "Article 180  \n",
      "Requirements specific to PD estimation  \n",
      "1. In quantifying the risk parameters to be associated with \n",
      "rating grades or pools, institutions shall apply the following \n",
      "requirements specific to PD estimation to exposures to \n",
      "corporates, institutions and central governments and central \n",
      "banks and for equity exposures where an institution uses the \n",
      "PD/LGD approach set out in Article 155(3):  \n",
      "(a) institutions shall estimate PDs by obligor grade from long \n",
      "run averages of one-year default rates. PD estimates for \n",
      "obligors that are highly leveraged or for obligors whose \n",
      "assets are predominantly traded assets shall reflect the \n",
      "performance of the underlying assets based on periods of \n",
      "stressed volatilities;  \n",
      "(b) for purchased corporate receivables institutions may \n",
      "estimate the EL by obligor grade from long run averages \n",
      "of one-year realised default rates;  \n",
      "(c) if an institution derives long run average estimates of PDs \n",
      "and LGDs for purchased corporate receivables from an \n",
      "estimate of EL, and an appropriate estimate of PD or \n",
      "LGD, the process for estimating total losses shall meet the \n",
      "overall standards for estimation of PD and LGD set out in\n",
      "\n",
      "tution for its estimates;  \n",
      "(d) the institution shall remain responsible for the integrity of \n",
      "its rating systems;  \n",
      "(e) the institution shall maintain sufficient in-house under ­\n",
      "standing of its rating systems, including the ability to effec ­\n",
      "tively monitor and audit the rating process.  \n",
      "Article 180  \n",
      "Requirements specific to PD estimation  \n",
      "1. In quantifying the risk parameters to be associated with \n",
      "rating grades or pools, institutions shall apply the following \n",
      "requirements specific to PD estimation to exposures to \n",
      "corporates, institutions and central governments and central \n",
      "banks and for equity exposures where an institution uses the \n",
      "PD/LGD approach set out in Article 155(3):  \n",
      "(a) institutions shall estimate PDs by obligor grade from long \n",
      "run averages of one-year default rates. PD estimates for \n",
      "obligors that are highly leveraged or for obligors whose \n",
      "assets are predominantly traded assets shall reflect the \n",
      "performance of the underlying assets based on periods of \n",
      "stressed volatilities;  \n",
      "(b) for purchased corporate receivables institutions may \n",
      "estimate the EL by obligor grade from long run averages \n",
      "of one-year realised default rates;  \n",
      "(c) if an institution derives long run average estimates of PDs \n",
      "and LGDs for purchased corporate receivables from an \n",
      "estimate of EL, and an appropriate estimate of PD or \n",
      "LGD, the process for estimating total losses shall meet the \n",
      "overall standards for estimation of PD and LGD set out in\n",
      "\n",
      "tution as part of the initial and on-going validation process;  \n",
      "(o) the initial and on-going validation of CCR exposure models \n",
      "shall assess whether or not the counterparty level and \n",
      "netting set exposure calculations of exposure are appro ­\n",
      "priate.  \n",
      "2. A measure that is more conservative than the metric used \n",
      "to calculate regulatory exposure value for every counterparty \n",
      "may be used in place of alpha multiplied by Effective EPE \n",
      "with the prior permission of the competent authorities. The \n",
      "degree of relative conservatism will be assessed upon initial \n",
      "approval by the competent authorities and at the regular super ­\n",
      "visory reviews of the EPE models. An institution shall validate \n",
      "the conservatism regularly. The on-going assessment of model \n",
      "performance shall cover all counterparties for which the models \n",
      "are used.  \n",
      "3. If back-testing indicates that a model is not sufficiently \n",
      "accurate, the competent authorities shall revoke its permission \n",
      "for the model, or impose appropriate measures to ensure that \n",
      "the model is improved promptly.EN 27.6.2013 Official Journal of the European Union L 176/185\n",
      "\n",
      "---\n",
      "\n",
      "Answer the question based on the above context: Should I calibrate my PD model before applying Margin of Conservatism?\n",
      "\u001B[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 8\u001B[0m\n\u001B[0;32m      4\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_excel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC:/Users/49171/OneDrive/Desktop/Programieren/Python/PDF_test/Final/Hackathon_Fragen.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m index, question \u001B[38;5;129;01min\u001B[39;00m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mQuestion\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m----> 8\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mqa_chain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mquery\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mquestion\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m     df\u001B[38;5;241m.\u001B[39mat[index, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mProvided Answer\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m response[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresult\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mQuestion no. \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(index\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m was processed\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\langchain\\chains\\base.py:164\u001B[0m, in \u001B[0;36mChain.invoke\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    163\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n\u001B[1;32m--> 164\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m    165\u001B[0m run_manager\u001B[38;5;241m.\u001B[39mon_chain_end(outputs)\n\u001B[0;32m    167\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m include_run_info:\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\langchain\\chains\\base.py:154\u001B[0m, in \u001B[0;36mChain.invoke\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    152\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_inputs(inputs)\n\u001B[0;32m    153\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m--> 154\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    155\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[0;32m    156\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(inputs)\n\u001B[0;32m    157\u001B[0m     )\n\u001B[0;32m    159\u001B[0m     final_outputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_outputs(\n\u001B[0;32m    160\u001B[0m         inputs, outputs, return_only_outputs\n\u001B[0;32m    161\u001B[0m     )\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\langchain\\chains\\retrieval_qa\\base.py:153\u001B[0m, in \u001B[0;36mBaseRetrievalQA._call\u001B[1;34m(self, inputs, run_manager)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    152\u001B[0m     docs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_docs(question)  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 153\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcombine_documents_chain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    154\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_documents\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdocs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquestion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquestion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_run_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_child\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    155\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_source_documents:\n\u001B[0;32m    158\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_key: answer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource_documents\u001B[39m\u001B[38;5;124m\"\u001B[39m: docs}\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:180\u001B[0m, in \u001B[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    178\u001B[0m     warned \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    179\u001B[0m     emit_warning()\n\u001B[1;32m--> 180\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\langchain\\chains\\base.py:603\u001B[0m, in \u001B[0;36mChain.run\u001B[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001B[0m\n\u001B[0;32m    598\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m(args[\u001B[38;5;241m0\u001B[39m], callbacks\u001B[38;5;241m=\u001B[39mcallbacks, tags\u001B[38;5;241m=\u001B[39mtags, metadata\u001B[38;5;241m=\u001B[39mmetadata)[\n\u001B[0;32m    599\u001B[0m         _output_key\n\u001B[0;32m    600\u001B[0m     ]\n\u001B[0;32m    602\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m args:\n\u001B[1;32m--> 603\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadata\u001B[49m\u001B[43m)\u001B[49m[\n\u001B[0;32m    604\u001B[0m         _output_key\n\u001B[0;32m    605\u001B[0m     ]\n\u001B[0;32m    607\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kwargs \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m args:\n\u001B[0;32m    608\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    609\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    610\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m but none were provided.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    611\u001B[0m     )\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:180\u001B[0m, in \u001B[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    178\u001B[0m     warned \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    179\u001B[0m     emit_warning()\n\u001B[1;32m--> 180\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\langchain\\chains\\base.py:381\u001B[0m, in \u001B[0;36mChain.__call__\u001B[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001B[0m\n\u001B[0;32m    349\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Execute the chain.\u001B[39;00m\n\u001B[0;32m    350\u001B[0m \n\u001B[0;32m    351\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    372\u001B[0m \u001B[38;5;124;03m        `Chain.output_keys`.\u001B[39;00m\n\u001B[0;32m    373\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    374\u001B[0m config \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    375\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallbacks\u001B[39m\u001B[38;5;124m\"\u001B[39m: callbacks,\n\u001B[0;32m    376\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtags\u001B[39m\u001B[38;5;124m\"\u001B[39m: tags,\n\u001B[0;32m    377\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: metadata,\n\u001B[0;32m    378\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: run_name,\n\u001B[0;32m    379\u001B[0m }\n\u001B[1;32m--> 381\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    382\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    383\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[43mRunnableConfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43mk\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    384\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_only_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_only_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    385\u001B[0m \u001B[43m    \u001B[49m\u001B[43minclude_run_info\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minclude_run_info\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    386\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\langchain\\chains\\base.py:164\u001B[0m, in \u001B[0;36mChain.invoke\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    163\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n\u001B[1;32m--> 164\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m    165\u001B[0m run_manager\u001B[38;5;241m.\u001B[39mon_chain_end(outputs)\n\u001B[0;32m    167\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m include_run_info:\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\langchain\\chains\\base.py:154\u001B[0m, in \u001B[0;36mChain.invoke\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    152\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_inputs(inputs)\n\u001B[0;32m    153\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m--> 154\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    155\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[0;32m    156\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(inputs)\n\u001B[0;32m    157\u001B[0m     )\n\u001B[0;32m    159\u001B[0m     final_outputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_outputs(\n\u001B[0;32m    160\u001B[0m         inputs, outputs, return_only_outputs\n\u001B[0;32m    161\u001B[0m     )\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\langchain\\chains\\combine_documents\\base.py:138\u001B[0m, in \u001B[0;36mBaseCombineDocumentsChain._call\u001B[1;34m(self, inputs, run_manager)\u001B[0m\n\u001B[0;32m    136\u001B[0m \u001B[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001B[39;00m\n\u001B[0;32m    137\u001B[0m other_keys \u001B[38;5;241m=\u001B[39m {k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m inputs\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_key}\n\u001B[1;32m--> 138\u001B[0m output, extra_return_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcombine_docs\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    139\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdocs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_run_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_child\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mother_keys\u001B[49m\n\u001B[0;32m    140\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    141\u001B[0m extra_return_dict[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_key] \u001B[38;5;241m=\u001B[39m output\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m extra_return_dict\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\langchain\\chains\\combine_documents\\stuff.py:257\u001B[0m, in \u001B[0;36mStuffDocumentsChain.combine_docs\u001B[1;34m(self, docs, callbacks, **kwargs)\u001B[0m\n\u001B[0;32m    255\u001B[0m inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_inputs(docs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    256\u001B[0m \u001B[38;5;66;03m# Call predict on the LLM.\u001B[39;00m\n\u001B[1;32m--> 257\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mllm_chain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m, {}\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\langchain\\chains\\llm.py:316\u001B[0m, in \u001B[0;36mLLMChain.predict\u001B[1;34m(self, callbacks, **kwargs)\u001B[0m\n\u001B[0;32m    301\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, callbacks: Callbacks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[0;32m    302\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001B[39;00m\n\u001B[0;32m    303\u001B[0m \n\u001B[0;32m    304\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    314\u001B[0m \u001B[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001B[39;00m\n\u001B[0;32m    315\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 316\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_key]\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:180\u001B[0m, in \u001B[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    178\u001B[0m     warned \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    179\u001B[0m     emit_warning()\n\u001B[1;32m--> 180\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\langchain\\chains\\base.py:381\u001B[0m, in \u001B[0;36mChain.__call__\u001B[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001B[0m\n\u001B[0;32m    349\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Execute the chain.\u001B[39;00m\n\u001B[0;32m    350\u001B[0m \n\u001B[0;32m    351\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    372\u001B[0m \u001B[38;5;124;03m        `Chain.output_keys`.\u001B[39;00m\n\u001B[0;32m    373\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    374\u001B[0m config \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    375\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallbacks\u001B[39m\u001B[38;5;124m\"\u001B[39m: callbacks,\n\u001B[0;32m    376\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtags\u001B[39m\u001B[38;5;124m\"\u001B[39m: tags,\n\u001B[0;32m    377\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: metadata,\n\u001B[0;32m    378\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: run_name,\n\u001B[0;32m    379\u001B[0m }\n\u001B[1;32m--> 381\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    382\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    383\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[43mRunnableConfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43mk\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    384\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_only_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_only_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    385\u001B[0m \u001B[43m    \u001B[49m\u001B[43minclude_run_info\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minclude_run_info\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    386\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\langchain\\chains\\base.py:164\u001B[0m, in \u001B[0;36mChain.invoke\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    163\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n\u001B[1;32m--> 164\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m    165\u001B[0m run_manager\u001B[38;5;241m.\u001B[39mon_chain_end(outputs)\n\u001B[0;32m    167\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m include_run_info:\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\langchain\\chains\\base.py:154\u001B[0m, in \u001B[0;36mChain.invoke\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    152\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_inputs(inputs)\n\u001B[0;32m    153\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m--> 154\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    155\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[0;32m    156\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(inputs)\n\u001B[0;32m    157\u001B[0m     )\n\u001B[0;32m    159\u001B[0m     final_outputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_outputs(\n\u001B[0;32m    160\u001B[0m         inputs, outputs, return_only_outputs\n\u001B[0;32m    161\u001B[0m     )\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\langchain\\chains\\llm.py:126\u001B[0m, in \u001B[0;36mLLMChain._call\u001B[1;34m(self, inputs, run_manager)\u001B[0m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_call\u001B[39m(\n\u001B[0;32m    122\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    123\u001B[0m     inputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any],\n\u001B[0;32m    124\u001B[0m     run_manager: Optional[CallbackManagerForChainRun] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    125\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m]:\n\u001B[1;32m--> 126\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    127\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcreate_outputs(response)[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\langchain\\chains\\llm.py:138\u001B[0m, in \u001B[0;36mLLMChain.generate\u001B[1;34m(self, input_list, run_manager)\u001B[0m\n\u001B[0;32m    136\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m run_manager\u001B[38;5;241m.\u001B[39mget_child() \u001B[38;5;28;01mif\u001B[39;00m run_manager \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm, BaseLanguageModel):\n\u001B[1;32m--> 138\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mllm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    139\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprompts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    140\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    141\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    142\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mllm_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    143\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    144\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    145\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm\u001B[38;5;241m.\u001B[39mbind(stop\u001B[38;5;241m=\u001B[39mstop, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm_kwargs)\u001B[38;5;241m.\u001B[39mbatch(\n\u001B[0;32m    146\u001B[0m         cast(List, prompts), {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallbacks\u001B[39m\u001B[38;5;124m\"\u001B[39m: callbacks}\n\u001B[0;32m    147\u001B[0m     )\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\langchain_core\\language_models\\llms.py:750\u001B[0m, in \u001B[0;36mBaseLLM.generate_prompt\u001B[1;34m(self, prompts, stop, callbacks, **kwargs)\u001B[0m\n\u001B[0;32m    742\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_prompt\u001B[39m(\n\u001B[0;32m    743\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    744\u001B[0m     prompts: List[PromptValue],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    747\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    748\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LLMResult:\n\u001B[0;32m    749\u001B[0m     prompt_strings \u001B[38;5;241m=\u001B[39m [p\u001B[38;5;241m.\u001B[39mto_string() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[1;32m--> 750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_strings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\langchain_core\\language_models\\llms.py:944\u001B[0m, in \u001B[0;36mBaseLLM.generate\u001B[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[0m\n\u001B[0;32m    929\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m get_llm_cache() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[0;32m    930\u001B[0m     run_managers \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    931\u001B[0m         callback_manager\u001B[38;5;241m.\u001B[39mon_llm_start(\n\u001B[0;32m    932\u001B[0m             dumpd(\u001B[38;5;28mself\u001B[39m),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    942\u001B[0m         )\n\u001B[0;32m    943\u001B[0m     ]\n\u001B[1;32m--> 944\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate_helper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    945\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprompts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mbool\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mnew_arg_supported\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    946\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    947\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output\n\u001B[0;32m    948\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(missing_prompts) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\langchain_core\\language_models\\llms.py:787\u001B[0m, in \u001B[0;36mBaseLLM._generate_helper\u001B[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001B[0m\n\u001B[0;32m    785\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m run_manager \u001B[38;5;129;01min\u001B[39;00m run_managers:\n\u001B[0;32m    786\u001B[0m         run_manager\u001B[38;5;241m.\u001B[39mon_llm_error(e, response\u001B[38;5;241m=\u001B[39mLLMResult(generations\u001B[38;5;241m=\u001B[39m[]))\n\u001B[1;32m--> 787\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m    788\u001B[0m flattened_outputs \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mflatten()\n\u001B[0;32m    789\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m manager, flattened_output \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(run_managers, flattened_outputs):\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\langchain_core\\language_models\\llms.py:774\u001B[0m, in \u001B[0;36mBaseLLM._generate_helper\u001B[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001B[0m\n\u001B[0;32m    764\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_generate_helper\u001B[39m(\n\u001B[0;32m    765\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    766\u001B[0m     prompts: List[\u001B[38;5;28mstr\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    770\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    771\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LLMResult:\n\u001B[0;32m    772\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    773\u001B[0m         output \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m--> 774\u001B[0m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    775\u001B[0m \u001B[43m                \u001B[49m\u001B[43mprompts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    776\u001B[0m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    777\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;66;43;03m# TODO: support multiple run managers\u001B[39;49;00m\n\u001B[0;32m    778\u001B[0m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    779\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    780\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    781\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[0;32m    782\u001B[0m             \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(prompts, stop\u001B[38;5;241m=\u001B[39mstop)\n\u001B[0;32m    783\u001B[0m         )\n\u001B[0;32m    784\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    785\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m run_manager \u001B[38;5;129;01min\u001B[39;00m run_managers:\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\langchain_community\\llms\\ollama.py:429\u001B[0m, in \u001B[0;36mOllama._generate\u001B[1;34m(self, prompts, stop, images, run_manager, **kwargs)\u001B[0m\n\u001B[0;32m    427\u001B[0m generations \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    428\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m prompt \u001B[38;5;129;01min\u001B[39;00m prompts:\n\u001B[1;32m--> 429\u001B[0m     final_chunk \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_stream_with_aggregation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    430\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    431\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    432\u001B[0m \u001B[43m        \u001B[49m\u001B[43mimages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    433\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    434\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    435\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    436\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    437\u001B[0m     generations\u001B[38;5;241m.\u001B[39mappend([final_chunk])\n\u001B[0;32m    438\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m LLMResult(generations\u001B[38;5;241m=\u001B[39mgenerations)\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\langchain_community\\llms\\ollama.py:347\u001B[0m, in \u001B[0;36m_OllamaCommon._stream_with_aggregation\u001B[1;34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001B[0m\n\u001B[0;32m    338\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_stream_with_aggregation\u001B[39m(\n\u001B[0;32m    339\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    340\u001B[0m     prompt: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    344\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    345\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m GenerationChunk:\n\u001B[0;32m    346\u001B[0m     final_chunk: Optional[GenerationChunk] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 347\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m stream_resp \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_generate_stream(prompt, stop, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    348\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m stream_resp:\n\u001B[0;32m    349\u001B[0m             chunk \u001B[38;5;241m=\u001B[39m _stream_response_to_generation_chunk(stream_resp)\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\langchain_community\\llms\\ollama.py:192\u001B[0m, in \u001B[0;36m_OllamaCommon._create_generate_stream\u001B[1;34m(self, prompt, stop, images, **kwargs)\u001B[0m\n\u001B[0;32m    184\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_create_generate_stream\u001B[39m(\n\u001B[0;32m    185\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    186\u001B[0m     prompt: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    189\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    190\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[\u001B[38;5;28mstr\u001B[39m]:\n\u001B[0;32m    191\u001B[0m     payload \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprompt\u001B[39m\u001B[38;5;124m\"\u001B[39m: prompt, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimages\u001B[39m\u001B[38;5;124m\"\u001B[39m: images}\n\u001B[1;32m--> 192\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_stream\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    193\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpayload\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpayload\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    194\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    195\u001B[0m \u001B[43m        \u001B[49m\u001B[43mapi_url\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_url\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/api/generate\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    196\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    197\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\langchain_community\\llms\\ollama.py:250\u001B[0m, in \u001B[0;36m_OllamaCommon._create_stream\u001B[1;34m(self, api_url, payload, stop, **kwargs)\u001B[0m\n\u001B[0;32m    244\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    245\u001B[0m     request_payload \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    246\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprompt\u001B[39m\u001B[38;5;124m\"\u001B[39m: payload\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprompt\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m    247\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimages\u001B[39m\u001B[38;5;124m\"\u001B[39m: payload\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimages\u001B[39m\u001B[38;5;124m\"\u001B[39m, []),\n\u001B[0;32m    248\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[0;32m    249\u001B[0m     }\n\u001B[1;32m--> 250\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mrequests\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpost\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    251\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mapi_url\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mContent-Type\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mapplication/json\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43mauth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_payload\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    259\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    260\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    261\u001B[0m response\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    262\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m200\u001B[39m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\requests\\api.py:115\u001B[0m, in \u001B[0;36mpost\u001B[1;34m(url, data, json, **kwargs)\u001B[0m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(url, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, json\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    104\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a POST request.\u001B[39;00m\n\u001B[0;32m    105\u001B[0m \n\u001B[0;32m    106\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 115\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpost\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\requests\\api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[1;34m(method, url, **kwargs)\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[1;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\requests\\sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[0;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[0;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[0;32m    587\u001B[0m }\n\u001B[0;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[1;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\requests\\sessions.py:703\u001B[0m, in \u001B[0;36mSession.send\u001B[1;34m(self, request, **kwargs)\u001B[0m\n\u001B[0;32m    700\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[0;32m    702\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[1;32m--> 703\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43madapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    705\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[0;32m    706\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\requests\\adapters.py:667\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[0;32m    664\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m TimeoutSauce(connect\u001B[38;5;241m=\u001B[39mtimeout, read\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[0;32m    666\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 667\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    668\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    669\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    670\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    671\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    672\u001B[0m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    673\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    674\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    675\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    676\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    677\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    678\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    679\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    681\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    682\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(err, request\u001B[38;5;241m=\u001B[39mrequest)\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\urllib3\\connectionpool.py:789\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001B[0m\n\u001B[0;32m    786\u001B[0m response_conn \u001B[38;5;241m=\u001B[39m conn \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m release_conn \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    788\u001B[0m \u001B[38;5;66;03m# Make the request on the HTTPConnection object\u001B[39;00m\n\u001B[1;32m--> 789\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    790\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    791\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    792\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    793\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    794\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    795\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    796\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    797\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    798\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresponse_conn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresponse_conn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    799\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpreload_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    800\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecode_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    801\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mresponse_kw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    802\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    804\u001B[0m \u001B[38;5;66;03m# Everything went great!\u001B[39;00m\n\u001B[0;32m    805\u001B[0m clean_exit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\urllib3\\connectionpool.py:536\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001B[0m\n\u001B[0;32m    534\u001B[0m \u001B[38;5;66;03m# Receive the response from the server\u001B[39;00m\n\u001B[0;32m    535\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 536\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    537\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (BaseSSLError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    538\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_timeout(err\u001B[38;5;241m=\u001B[39me, url\u001B[38;5;241m=\u001B[39murl, timeout_value\u001B[38;5;241m=\u001B[39mread_timeout)\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\urllib3\\connection.py:507\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    504\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mresponse\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HTTPResponse\n\u001B[0;32m    506\u001B[0m \u001B[38;5;66;03m# Get the response from http.client.HTTPConnection\u001B[39;00m\n\u001B[1;32m--> 507\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    509\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    510\u001B[0m     assert_header_parsing(httplib_response\u001B[38;5;241m.\u001B[39mmsg)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\http\\client.py:1344\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1342\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1343\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1344\u001B[0m         \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbegin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1345\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m:\n\u001B[0;32m   1346\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\http\\client.py:307\u001B[0m, in \u001B[0;36mHTTPResponse.begin\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    305\u001B[0m \u001B[38;5;66;03m# read until we get a non-100 response\u001B[39;00m\n\u001B[0;32m    306\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 307\u001B[0m     version, status, reason \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    308\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m status \u001B[38;5;241m!=\u001B[39m CONTINUE:\n\u001B[0;32m    309\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\http\\client.py:268\u001B[0m, in \u001B[0;36mHTTPResponse._read_status\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    267\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_read_status\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 268\u001B[0m     line \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_MAXLINE\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miso-8859-1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    269\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(line) \u001B[38;5;241m>\u001B[39m _MAXLINE:\n\u001B[0;32m    270\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m LineTooLong(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstatus line\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\socket.py:669\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m    667\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    668\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 669\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    670\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[0;32m    671\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "d953b1d8a2ad8be9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **2. Code to create a Web application for the RAG**",
   "id": "d79e47037cd74bfa"
  },
  {
   "cell_type": "code",
   "id": "c5cf37f5-0b6e-42ef-b7e7-a37e2c630aa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T13:20:54.860747Z",
     "start_time": "2024-10-14T13:20:54.728252Z"
    }
   },
   "source": [
    "with st.sidebar:\n",
    "    st.image(\"https://upload.wikimedia.org/wikipedia/commons/4/49/ING_Group_N.V._Logo.svg\")\n",
    "    st.title(\"Regulatory AI Search Engine\")\n",
    "    st.markdown('''\n",
    "    ## About            \n",
    "    This application is a regulatory chatbot using a local Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "\n",
    "    ''')\n",
    "    st.markdown(\"---\")\n",
    "    st.markdown('''**Made with :orange_heart: by the Algorithm Alchemists**''')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    st.header(\"Chat with PDF :left_speech_bubble:\")\n",
    "\n",
    "    # Initialize chat history if not already in session state\n",
    "    if \"chat_history\" not in st.session_state:\n",
    "        st.session_state.chat_history = []\n",
    "        # Add initial message from the assistant\n",
    "        welcome_message = {\"role\": \"assistant\", \"message\": \"Hi, how can I help you today?\"}\n",
    "        st.session_state.chat_history.append(welcome_message)\n",
    "\n",
    "    # Display chat history\n",
    "    for chat in st.session_state.chat_history:\n",
    "        with st.chat_message(chat[\"role\"]):\n",
    "            st.markdown(chat[\"message\"])\n",
    "            if \"Sources\" in chat[\"message\"]:\n",
    "                with st.expander(\"🔍 Sources\", expanded=False):\n",
    "                    st.markdown(chat[\"message\"])\n",
    "\n",
    "    # User input\n",
    "    if user_input := st.chat_input(\"Type here your question:\", key=\"user_input\"):\n",
    "        user_message = {\"role\": \"user\", \"message\": user_input}\n",
    "        st.session_state.chat_history.append(user_message)\n",
    "\n",
    "        # Display user message\n",
    "        with st.chat_message(\"user\"):\n",
    "            st.markdown(user_input)\n",
    "\n",
    "        # Generate assistant's response\n",
    "        with st.chat_message(\"assistant\"):\n",
    "            with st.spinner(\"Assistant is typing...\"):\n",
    "                response = qa_chain.invoke({\"query\": user_input})\n",
    "            message_placeholder = st.empty()\n",
    "            full_response = \"\"\n",
    "            for chunk in response['result'].split():\n",
    "                full_response += chunk + \" \"\n",
    "                time.sleep(0.05)\n",
    "                message_placeholder.markdown(full_response + \"▌\")\n",
    "\n",
    "        assistant_message = {\"role\": \"assistant\", \"message\": response['result']}\n",
    "        st.session_state.chat_history.append(assistant_message)\n",
    "\n",
    "        # Display sources\n",
    "        full_sources = []\n",
    "        results = retriever.invoke(user_input)\n",
    "        for doc in results:\n",
    "            source_path = doc.metadata.get('source', 'No source available')\n",
    "            source_filename = os.path.basename(source_path)\n",
    "            filename_without_extension = os.path.splitext(source_filename)[0]\n",
    "            source = f\"Source: {filename_without_extension}\"\n",
    "            page = f\"Page: {doc.metadata.get('page', 'No page available')}\"\n",
    "            if page_number != 'No page available':\n",
    "                page_number = int(page_number) + 1\n",
    "            full_source = f\"{source}, {page_number}\"\n",
    "            full_sources.append(full_source)\n",
    "        final_source = \"\\n\".join(full_sources)\n",
    "        source_message = {\"role\": \"assistant\", \"message\": final_source}\n",
    "        st.session_state.chat_history.append(source_message)\n",
    "\n",
    "        with st.expander(\"🔍 Sources\", expanded=False):\n",
    "            st.markdown(final_source)\n",
    "    else:\n",
    "        st.write(\"Please type your question regarding the CRR, MaRisk or the German Banking Act.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 15:20:54.736 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-14 15:20:54.741 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-14 15:20:54.832 \n",
      "  \u001B[33m\u001B[1mWarning:\u001B[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\49171\\PycharmProjects\\pythonProject3\\.venv\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-10-14 15:20:54.833 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-14 15:20:54.834 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-14 15:20:54.834 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-14 15:20:54.834 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-14 15:20:54.835 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-14 15:20:54.835 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-14 15:20:54.836 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-14 15:20:54.836 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-14 15:20:54.836 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-14 15:20:54.837 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-14 15:20:54.838 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-14 15:20:54.838 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-14 15:20:54.839 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-14 15:20:54.841 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-14 15:20:54.842 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-14 15:20:54.842 Session state does not function when running a script without `streamlit run`\n",
      "2024-10-14 15:20:54.843 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-14 15:20:54.845 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-14 15:20:54.846 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-14 15:20:54.847 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
